---
phase: 01-foundations
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/trace/__init__.py
  - src/trace/_version.py
  - src/trace/exceptions.py
  - src/trace/protocols.py
  - src/trace/models/__init__.py
  - src/trace/models/content.py
  - src/trace/models/commit.py
  - src/trace/models/annotations.py
  - src/trace/models/config.py
  - src/trace/storage/__init__.py
  - src/trace/storage/schema.py
  - src/trace/storage/types.py
  - src/trace/storage/engine.py
  - src/trace/storage/repositories.py
  - src/trace/storage/sqlite.py
  - tests/__init__.py
  - tests/conftest.py
  - tests/strategies.py
  - tests/test_models/__init__.py
  - tests/test_models/test_content.py
  - tests/test_storage/__init__.py
  - tests/test_storage/test_schema.py
  - tests/test_storage/test_repositories.py
autonomous: true

must_haves:
  truths:
    - "All 7 content types (instruction, dialogue, tool_io, reasoning, artifact, output, freeform) validate correctly via Pydantic discriminated union"
    - "Custom content types can be registered and validated at runtime"
    - "SQLAlchemy schema creates all tables (blobs, commits, refs, annotations) in SQLite"
    - "Content-addressable blobs are deduplicated (same content = same hash = stored once)"
    - "Repository pattern abstracts all DB access behind ABC interfaces with SQLite implementations"
    - "Commits, blobs, refs, and annotations can be stored and retrieved correctly through repository layer"
  artifacts:
    - path: "src/trace/models/content.py"
      provides: "7 content type models + discriminated union + custom type registry"
      contains: "ContentPayload"
    - path: "src/trace/storage/schema.py"
      provides: "ORM models: BlobRow, CommitRow, RefRow, AnnotationRow"
      contains: "class CommitRow"
    - path: "src/trace/storage/repositories.py"
      provides: "Abstract repository interfaces"
      contains: "class CommitRepository"
    - path: "src/trace/storage/sqlite.py"
      provides: "SQLite implementations of all repositories"
      contains: "class SqliteCommitRepository"
    - path: "src/trace/protocols.py"
      provides: "TokenCounter, Materializer protocols"
      contains: "class TokenCounter"
  key_links:
    - from: "src/trace/storage/types.py"
      to: "src/trace/models/content.py"
      via: "PydanticJSON TypeDecorator bridges Pydantic models to SQLAlchemy JSON columns"
      pattern: "PydanticJSON"
    - from: "src/trace/storage/sqlite.py"
      to: "src/trace/storage/repositories.py"
      via: "SQLite repos implement abstract repository interfaces"
      pattern: "class Sqlite.*Repository.*Repository"
    - from: "src/trace/storage/sqlite.py"
      to: "src/trace/storage/schema.py"
      via: "SQLite repos use ORM models for queries"
      pattern: "CommitRow|BlobRow|RefRow|AnnotationRow"
---

<objective>
Build the complete data foundation for Trace: project scaffolding, Pydantic domain models (content types, commit info, annotations, config), SQLAlchemy ORM schema, the PydanticJSON TypeDecorator bridge, repository pattern (ABCs + SQLite implementations), and the engine/session factory. This is the load-bearing layer everything else depends on.

Purpose: Every subsequent plan (commit engine, materializer, Repo class) imports from these modules. Getting the data model and storage right here prevents cascading issues.
Output: Working storage layer with full test coverage -- all tables create, all CRUD operations work, all content types validate.
</objective>

<execution_context>
@C:\Users\jinwi\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jinwi\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@C:\Users\jinwi\programming_files_NEW\Trace\.planning\PROJECT.md
@C:\Users\jinwi\programming_files_NEW\Trace\.planning\ROADMAP.md
@C:\Users\jinwi\programming_files_NEW\Trace\.planning\STATE.md
@C:\Users\jinwi\programming_files_NEW\Trace\.planning\phases\01-foundations\01-CONTEXT.md
@C:\Users\jinwi\programming_files_NEW\Trace\.planning\phases\01-foundations\01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Project scaffolding, domain models, and protocols</name>
  <files>
    pyproject.toml
    src/trace/__init__.py
    src/trace/_version.py
    src/trace/exceptions.py
    src/trace/protocols.py
    src/trace/models/__init__.py
    src/trace/models/content.py
    src/trace/models/commit.py
    src/trace/models/annotations.py
    src/trace/models/config.py
    tests/__init__.py
    tests/strategies.py
    tests/test_models/__init__.py
    tests/test_models/test_content.py
  </files>
  <action>
    **1. Project setup (pyproject.toml):**
    Create pyproject.toml with:
    - name: "trace-context" (or "trace" if available -- the import name is `trace` via `src/trace/`)
    - Python >=3.10
    - Dependencies: sqlalchemy>=2.0.46,<2.2; pydantic>=2.10,<3.0; tiktoken>=0.12.0; typing-extensions>=4.12
    - Dev dependencies group: pytest>=8.0; hypothesis>=6.150; pytest-cov>=7.0; ruff>=0.15; mypy>=1.14
    - Use `[project]` table (PEP 621), `[tool.pytest.ini_options]` with testpaths=["tests"]
    - Package discovery: src layout (`packages = [{include = "trace", from = "src"}]` or equivalent)
    - IMPORTANT: The package import name is `trace` but note this shadows Python's stdlib `trace` module. Use `tract` as the distribution name on PyPI. The import path is `from trace.models.content import ...` etc.
    - Actually -- to avoid shadowing stdlib `trace`, use the package name `context_trace` as the import name. Place source at `src/context_trace/`. All imports will be `from context_trace.models.content import ...`.

    Wait -- let me reconsider. The RESEARCH.md and CONTEXT.md consistently use `trace` as the package name and `src/trace/` as the path. The user's project is called "Trace". Follow the established convention from research: use `src/trace/` as the source path and `trace` as the import name. The stdlib `trace` module is rarely used and this is a library that will be installed in its own venv. Keep it simple.

    Use `src/trace/` with import name `trace`. Build system: use hatchling or setuptools with src layout.

    Run `uv add sqlalchemy pydantic tiktoken typing-extensions` and `uv add --dev pytest hypothesis pytest-cov ruff mypy` to install deps.

    **2. Exception hierarchy (exceptions.py):**
    - `TraceError(Exception)` -- base
    - `CommitNotFoundError(TraceError)` -- commit hash lookup failed
    - `BlobNotFoundError(TraceError)` -- blob hash lookup failed
    - `ValidationError(TraceError)` -- content validation failed
    - `BudgetExceededError(TraceError)` -- token budget exceeded (with current_tokens, max_tokens attrs)
    - `EditTargetError(TraceError)` -- edit targets invalid commit (another edit, or nonexistent)
    - `DuplicateRefError(TraceError)` -- ref already exists

    **3. Protocols (protocols.py):**
    Define Protocol classes using `typing.Protocol` (with `runtime_checkable`):
    - `TokenCounter`: `count_text(self, text: str) -> int`, `count_messages(self, messages: list[dict]) -> int`
    - `Materializer`: `materialize(self, commits: list, *, as_of: str | datetime | None = None, include_edit_annotations: bool = False) -> MaterializedContext`
    - `TokenUsageExtractor`: `extract(self, api_response: dict) -> TokenUsage | None` (for Phase 3, define protocol now)

    Also define frozen dataclasses in protocols.py:
    - `Message(role: str, content: str, name: str | None = None)`
    - `MaterializedContext(messages: list[Message], token_count: int, commit_count: int, token_source: str)`
    - `TokenUsage(prompt_tokens: int, completion_tokens: int, total_tokens: int)`

    **4. Content type system (models/content.py):**
    Following RESEARCH.md Pattern 2 exactly:
    - 7 Pydantic BaseModel subclasses: `InstructionContent`, `DialogueContent`, `ToolIOContent`, `ReasoningContent`, `ArtifactContent`, `OutputContent`, `FreeformContent`
    - Each has `content_type: Literal["typename"] = "typename"` as discriminator field
    - `ContentPayload` = Annotated Union with `Field(discriminator="content_type")`
    - `ContentTypeHints` frozen dataclass with: default_priority, materialization_order, default_role, compression_priority, aggregation_rule
    - `BUILTIN_TYPE_HINTS` dict mapping type name -> ContentTypeHints (copy from RESEARCH.md)
    - `_custom_type_registry: dict[str, type[BaseModel]]` module-level
    - `register_content_type(name, model)` function
    - `validate_content(data: dict) -> BaseModel` function that checks custom registry first, then falls back to built-in discriminated union

    Field schemas per type (from CONTEXT.md):
    - InstructionContent: text: str
    - DialogueContent: role: Literal["user", "assistant", "system"], text: str, name: str | None = None
    - ToolIOContent: tool_name: str, direction: Literal["call", "result"], payload: dict, status: Literal["success", "error"] | None = None
    - ReasoningContent: text: str
    - ArtifactContent: artifact_type: str, content: str, language: str | None = None
    - OutputContent: text: str, format: Literal["text", "markdown", "json"] = "text"
    - FreeformContent: payload: dict

    **5. Commit model (models/commit.py):**
    - `CommitOperation` enum: APPEND, EDIT, DELETE
    - `CommitInfo` Pydantic model: commit_hash, repo_id, parent_hash (optional), content_hash, content_type, operation (CommitOperation), reply_to (optional), message (optional), token_count, cumulative_tokens, metadata (optional dict), created_at (datetime)
    - This is the SDK-facing model (not ORM). Used when returning commit data to users.

    **6. Annotation model (models/annotations.py):**
    - `Priority` enum: SKIP, NORMAL, PINNED
    - `PriorityAnnotation` Pydantic model: id (optional int), repo_id, target_hash, priority (Priority), reason (optional str), created_at (datetime)
    - `DEFAULT_TYPE_PRIORITIES: dict[str, Priority]` mapping content type names to default priorities (instruction -> PINNED, all others -> NORMAL)

    **7. Config model (models/config.py):**
    - `BudgetAction` enum: WARN, REJECT, CALLBACK
    - `TokenBudgetConfig` Pydantic model: max_tokens (optional int, None=unlimited), action (BudgetAction, default WARN), callback (optional Callable[[int, int], None])
    - `RepoConfig` Pydantic model: db_path (str, default ":memory:"), tokenizer_encoding (str, default "o200k_base"), token_budget (optional TokenBudgetConfig), default_branch (str, default "main")
    - Set `model_config = {"arbitrary_types_allowed": True}` on models with Callable fields

    **8. Hypothesis strategies (tests/strategies.py):**
    Copy the strategy definitions from RESEARCH.md. Create strategies for all 7 content types plus `any_content` combined strategy.

    **9. Content type tests (tests/test_models/test_content.py):**
    - Test each built-in type validates with correct data
    - Test discriminated union selects correct type based on content_type field
    - Test invalid content_type raises ValidationError
    - Test custom type registration and validation via `register_content_type` / `validate_content`
    - Property test: round-trip `model_dump()` -> `model_validate()` for all content types
    - Test BUILTIN_TYPE_HINTS has entries for all 7 types

    **10. Package init files:**
    - `src/trace/__init__.py`: version import, docstring. Public API exports will be added in Plan 03.
    - `src/trace/_version.py`: `__version__ = "0.1.0"`
    - `src/trace/models/__init__.py`: re-export key models
    - `tests/__init__.py`: empty
    - `tests/test_models/__init__.py`: empty
  </action>
  <verify>
    Run: `cd C:\Users\jinwi\programming_files_NEW\Trace && python -m pytest tests/test_models/test_content.py -v`
    All content type tests pass. Pydantic models validate, discriminated union dispatches correctly, custom type registration works.
  </verify>
  <done>
    - pyproject.toml exists with all Phase 1 dependencies
    - All 7 content types validate via discriminated union
    - Custom types register and validate via registry
    - CommitInfo, PriorityAnnotation, RepoConfig, TokenBudgetConfig models exist and validate
    - TokenCounter, Materializer, TokenUsageExtractor protocols defined
    - Exception hierarchy defined
    - Content model tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: SQLAlchemy ORM schema, TypeDecorator bridge, repositories, and storage tests</name>
  <files>
    src/trace/storage/__init__.py
    src/trace/storage/schema.py
    src/trace/storage/types.py
    src/trace/storage/engine.py
    src/trace/storage/repositories.py
    src/trace/storage/sqlite.py
    tests/conftest.py
    tests/test_storage/__init__.py
    tests/test_storage/test_schema.py
    tests/test_storage/test_repositories.py
  </files>
  <action>
    **1. PydanticJSON TypeDecorator (storage/types.py):**
    Implement exactly as shown in RESEARCH.md Pattern 1:
    - `PydanticJSON(TypeDecorator)` with `impl = JSON`, `cache_ok = True`
    - `process_bind_param`: model_dump(mode="json")
    - `process_result_value`: model_validate (handles both dict and str input)
    - Include `coerce_compared_value` override

    **2. ORM Schema (storage/schema.py):**
    Implement exactly as shown in RESEARCH.md code example:
    - `Base(DeclarativeBase)` -- the base class for all ORM models
    - `BlobRow`: content_hash (PK, String(64)), payload_json (Text), byte_size (Integer), token_count (Integer), created_at (DateTime)
    - `CommitRow`: commit_hash (PK, String(64)), repo_id (String(64), indexed), parent_hash (nullable FK to commits.commit_hash), content_hash (FK to blobs.content_hash), content_type (String(50)), operation (Enum CommitOperation), reply_to (nullable FK to commits.commit_hash), message (nullable Text), token_count (Integer), cumulative_tokens (Integer), metadata_json (nullable JSON), created_at (DateTime). Include relationships to blob and parent. Include composite indexes: (repo_id, created_at), (repo_id, content_type), (reply_to).
    - `RefRow`: composite PK (repo_id, ref_name), commit_hash (nullable FK), symbolic_target (nullable String)
    - `AnnotationRow`: id (autoincrement PK), repo_id (String(64), indexed), target_hash (FK to commits), priority (Enum Priority), reason (nullable Text), created_at (DateTime). Index on (target_hash, created_at).

    IMPORTANT: Import CommitOperation from models.commit and Priority from models.annotations -- do NOT redefine them. The ORM uses the same Python enums as the domain models.

    **3. Engine/session factory (storage/engine.py):**
    - `create_trace_engine(db_path: str = ":memory:") -> Engine` with SQLite pragmas (WAL, busy_timeout=5000, synchronous=NORMAL, foreign_keys=ON) via event listener
    - `create_session_factory(engine) -> sessionmaker` with expire_on_commit=False
    - `init_db(engine)` calls `Base.metadata.create_all(engine)`

    **4. Abstract repositories (storage/repositories.py):**
    Define ABC interfaces (do NOT import SQLAlchemy here -- pure abstract):
    - `CommitRepository(ABC)`: get(hash) -> CommitRow|None, save(commit), get_ancestors(hash, limit) -> list, get_by_type(content_type, repo_id) -> list, get_children(hash) -> list
    - `BlobRepository(ABC)`: get(hash) -> BlobRow|None, save_if_absent(blob) -> None
    - `RefRepository(ABC)`: get_head(repo_id) -> str|None, update_head(repo_id, hash), get_branch(repo_id, branch_name) -> str|None, set_branch(repo_id, branch_name, hash), list_branches(repo_id) -> list[str]
    - `AnnotationRepository(ABC)`: get_latest(target_hash) -> AnnotationRow|None, save(annotation), get_history(target_hash) -> list, batch_get_latest(target_hashes: list[str]) -> dict[str, AnnotationRow] (for materialization -- avoids N+1)

    **5. SQLite implementations (storage/sqlite.py):**
    Implement all 4 repository ABCs using SQLAlchemy 2.0-style queries (`select()` + `session.execute()`):
    - `SqliteCommitRepository(CommitRepository)`: takes Session in __init__
    - `SqliteBlobRepository(BlobRepository)`: save_if_absent checks existence before insert (content-addressable dedup)
    - `SqliteRefRepository(RefRepository)`: HEAD is stored as ref_name="HEAD", branches as ref_name="refs/heads/{name}"
    - `SqliteAnnotationRepository(AnnotationRepository)`: batch_get_latest uses a single query with subquery for max(created_at) per target_hash

    All repos take `Session` in constructor. Use `session.execute(select(...))` pattern, NOT `session.query()`.

    **6. Storage __init__.py:**
    Re-export: create_trace_engine, create_session_factory, init_db, and all Sqlite*Repository classes.

    **7. Test conftest (tests/conftest.py):**
    - `engine` fixture: in-memory SQLite via create_trace_engine(":memory:")
    - `session` fixture: session from engine with rollback after test
    - `sample_repo_id` fixture: returns "test-repo-001"
    - `commit_repos` / `blob_repos` / etc. fixtures that create Sqlite*Repository instances

    **8. Schema tests (tests/test_storage/test_schema.py):**
    - Test all tables are created (check table names in metadata)
    - Test BlobRow round-trip: create, save, query by PK
    - Test CommitRow round-trip with all fields populated
    - Test RefRow composite PK works
    - Test AnnotationRow autoincrement ID
    - Test foreign key constraints (commit with invalid content_hash should fail)
    - Test indexes exist on expected columns

    **9. Repository tests (tests/test_storage/test_repositories.py):**
    - Test SqliteBlobRepository.save_if_absent deduplication (save same blob twice, only one row)
    - Test SqliteCommitRepository.get returns None for nonexistent hash
    - Test SqliteCommitRepository.save and get round-trip
    - Test SqliteCommitRepository.get_ancestors returns correct chain
    - Test SqliteRefRepository.update_head and get_head
    - Test SqliteRefRepository branch operations (set, get, list)
    - Test SqliteAnnotationRepository.save and get_latest returns most recent
    - Test SqliteAnnotationRepository.batch_get_latest for multiple targets
    - Test SqliteAnnotationRepository.get_history returns all annotations in order
  </action>
  <verify>
    Run: `cd C:\Users\jinwi\programming_files_NEW\Trace && python -m pytest tests/test_storage/ tests/test_models/ -v`
    All storage and model tests pass. Tables create correctly. CRUD operations work through repository layer. Blob deduplication works.
  </verify>
  <done>
    - SQLAlchemy schema creates 4 tables (blobs, commits, refs, annotations) with correct columns, constraints, and indexes
    - PydanticJSON TypeDecorator correctly serializes/deserializes Pydantic models to JSON columns
    - All 4 repository ABCs defined with clear interfaces
    - All 4 SQLite repository implementations work correctly
    - Blob deduplication verified (same content_hash stored once)
    - All storage tests and model tests pass
  </done>
</task>

</tasks>

<verification>
Run the full test suite:
```bash
cd C:\Users\jinwi\programming_files_NEW\Trace && python -m pytest tests/ -v --tb=short
```

Verify imports work:
```bash
python -c "from trace.models.content import ContentPayload, validate_content; print('Models OK')"
python -c "from trace.storage import create_trace_engine, SqliteCommitRepository; print('Storage OK')"
python -c "from trace.protocols import TokenCounter, Materializer, Message; print('Protocols OK')"
```

Verify schema creation:
```bash
python -c "
from trace.storage.engine import create_trace_engine
from trace.storage.schema import Base
e = create_trace_engine(':memory:')
tables = list(Base.metadata.tables.keys())
assert set(tables) >= {'blobs', 'commits', 'refs', 'annotations'}, f'Missing tables: {tables}'
print(f'Tables created: {tables}')
"
```
</verification>

<success_criteria>
- pyproject.toml installs all Phase 1 dependencies successfully
- All 7 content types validate via Pydantic discriminated union
- Custom content types register and validate at runtime
- SQLite schema creates 4 tables with correct columns, FKs, and indexes
- Repository CRUD operations work for all 4 entity types
- Blob deduplication stores identical content only once
- All tests pass (model tests + storage tests)
- No SQLAlchemy imports in models/ or protocols.py (clean layer separation)
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundations/01-01-SUMMARY.md`
</output>
