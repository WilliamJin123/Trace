---
phase: 07-agent-toolkit-orchestrator
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/tract/toolkit/__init__.py
  - src/tract/toolkit/definitions.py
  - src/tract/toolkit/profiles.py
  - src/tract/toolkit/executor.py
  - src/tract/toolkit/models.py
  - tests/test_toolkit.py
autonomous: true

must_haves:
  truths:
    - "User can call Tract.as_tools() and receive a list of tool definition dicts"
    - "User can specify profile='self' or profile='supervisor' to get different tool subsets with scenario-appropriate descriptions"
    - "User can override individual tool descriptions on top of any profile"
    - "User can get tool definitions in OpenAI or Anthropic format"
    - "ToolExecutor can dispatch a tool call dict to the correct Tract method and return a structured result"
  artifacts:
    - path: "src/tract/toolkit/__init__.py"
      provides: "Public exports for toolkit module"
      exports: ["ToolDefinition", "ToolProfile", "ToolConfig", "ToolExecutor", "ToolResult", "ToolCall", "get_all_tools", "get_profile", "SELF_PROFILE", "SUPERVISOR_PROFILE", "FULL_PROFILE"]
      note: "ToolCall is re-exported from tract.orchestrator.models (canonical location, owned by Plan 02)"
    - path: "src/tract/toolkit/models.py"
      provides: "Toolkit data models"
      contains: "class ToolDefinition"
    - path: "src/tract/toolkit/definitions.py"
      provides: "Hand-crafted tool definitions for all Tract operations"
      min_lines: 200
    - path: "src/tract/toolkit/profiles.py"
      provides: "Built-in profiles with curated tool subsets"
      contains: "SELF_PROFILE"
    - path: "src/tract/toolkit/executor.py"
      provides: "ToolExecutor that dispatches tool calls to Tract methods"
      contains: "class ToolExecutor"
    - path: "tests/test_toolkit.py"
      provides: "Tests for toolkit module"
      min_lines: 150
  key_links:
    - from: "src/tract/toolkit/definitions.py"
      to: "src/tract/tract.py"
      via: "handler lambdas that call Tract public methods"
      pattern: "handler=lambda"
    - from: "src/tract/toolkit/profiles.py"
      to: "src/tract/toolkit/definitions.py"
      via: "profiles reference tool names from definitions"
      pattern: "tool_configs"
    - from: "src/tract/toolkit/executor.py"
      to: "src/tract/toolkit/models.py"
      via: "executor returns ToolResult instances"
      pattern: "ToolResult"
---

<objective>
Build the Agent Toolkit layer: tool definitions, profiles, executor, and data models that expose Tract operations as LLM-consumable tool schemas.

Purpose: This is the foundation that both the built-in orchestrator (Plan 03) and any external agent will use to interact with Tract programmatically via tool calling. The toolkit is independently useful without the orchestrator.

Output: `src/tract/toolkit/` package with models, definitions, profiles, executor, and comprehensive tests.
</objective>

<execution_context>
@C:\Users\jinwi\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jinwi\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-agent-toolkit-orchestrator/07-CONTEXT.md
@.planning/phases/07-agent-toolkit-orchestrator/07-RESEARCH.md
@src/tract/tract.py
@src/tract/models/policy.py
@src/tract/policy/evaluator.py
@src/tract/exceptions.py
@src/tract/__init__.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Toolkit Models, Tool Definitions, and Profiles</name>
  <files>
    src/tract/toolkit/__init__.py
    src/tract/toolkit/models.py
    src/tract/toolkit/definitions.py
    src/tract/toolkit/profiles.py
  </files>
  <action>
Create the `src/tract/toolkit/` package with four modules.

**models.py** -- Frozen dataclasses for toolkit types:
- `ToolDefinition(frozen=True)`: name (str), description (str), parameters (dict -- JSON Schema), handler (Callable[..., object]). Methods: `to_openai() -> dict` (returns `{"type": "function", "function": {"name": ..., "description": ..., "parameters": ...}}`), `to_anthropic() -> dict` (returns `{"name": ..., "description": ..., "input_schema": ...}`).
- `ToolConfig(frozen=True)`: enabled (bool, default True), description (str | None, default None).
- `ToolProfile`: name (str), tool_configs (dict[str, ToolConfig]). Method: `filter_tools(all_tools: list[ToolDefinition]) -> list[ToolDefinition]` -- returns only tools present in tool_configs where enabled=True, with description overridden if config provides one. Use `dataclasses.replace()` to override description.
- `ToolResult(frozen=True)`: tool_name (str), success (bool), output (str, default ""), error (str, default "").

Note: `ToolCall` is NOT defined here. The canonical `ToolCall(frozen=True)` lives in `orchestrator/models.py` (Plan 02). If toolkit code needs ToolCall, import from `tract.orchestrator.models`. The toolkit __init__.py re-exports ToolCall from orchestrator for convenience.

Follow codebase conventions: `from __future__ import annotations`, `if TYPE_CHECKING:` for heavy imports, `logger = logging.getLogger(__name__)`.

**definitions.py** -- A function `get_all_tools(tract: Tract) -> list[ToolDefinition]` that returns hand-crafted tool definitions for these Tract operations:

1. `commit` -- Record new context (content as JSON dict, operation, message, response_to, metadata, generation_config)
2. `compile` -- Compile current context into LLM-ready messages (returns token count + message count summary)
3. `annotate` -- Set priority on a commit (target_hash, priority: "pinned"/"normal"/"skip", reason)
4. `status` -- Get current tract status (returns branch name, HEAD, token count, budget %)
5. `log` -- View recent commit history (limit, op_filter)
6. `diff` -- Compare two commits (commit_a, commit_b)
7. `compress` -- Compress commit range into summary (target_tokens, from_commit, to_commit, instructions). Always use auto_commit=True.
8. `branch` -- Create a new branch (name, source, switch)
9. `switch` -- Switch to a different branch (target)
10. `merge` -- Merge a branch into current (source, message)
11. `reset` -- Reset HEAD to a previous commit (target, mode: soft/hard)
12. `checkout` -- Checkout a specific commit for read-only inspection (target)
13. `gc` -- Run garbage collection (min_age_hours, keep_pinned, keep_branches)
14. `list_branches` -- List all branches
15. `get_commit` -- Get details of a specific commit (commit_hash)

For each tool: hand-write a clear, action-oriented description. The description is the most important part -- it tells the LLM WHEN and WHY to use the tool. Include "type": "object" in parameters with proper JSON Schema (types, descriptions, required array). The handler is a lambda that calls the corresponding Tract method with appropriate argument mapping. For tools that return complex objects, the handler should convert the result to a human-readable string summary (not raw repr).

Important: handler lambdas should NOT store direct references to `tract` at module level. Each call to `get_all_tools(tract)` builds fresh lambdas bound to the passed `tract` instance.

Important: handler lambdas must use **explicit parameter whitelisting**, not `**kwargs` passthrough. This prevents unexpected LLM-hallucinated arguments from flowing through. Example: `handler=lambda target_tokens=None, from_commit=None, to_commit=None, instructions=None: tract.compress(target_tokens=target_tokens, from_commit=from_commit, to_commit=to_commit, instructions=instructions, auto_commit=True)`. Each handler explicitly names only the parameters defined in its JSON Schema.

Note: Tools that invoke LLM-powered operations (compress, merge) require `tract.configure_llm()` to have been called. If not configured, the ToolExecutor's try/except will catch the error and return `ToolResult(success=False, error="...")` -- the LLM can then reason about the failure. Document this dependency in the tool descriptions for compress and merge: "Requires an LLM client to be configured via tract.configure_llm()."

**profiles.py** -- Three built-in profiles as module-level constants:

- `SELF_PROFILE` (name="self"): Tools for an agent managing its OWN context. Include: commit, compile, annotate, status, log, compress, branch, switch, reset. Exclude: merge, checkout, gc, diff, list_branches, get_commit (advanced ops). Override descriptions to be self-referential: "Compress YOUR context history...", "Check YOUR current status...".
- `SUPERVISOR_PROFILE` (name="supervisor"): Tools for managing ANOTHER agent's context. Include: all tools. Override descriptions to be managerial: "Compress the managed agent's context...", "Check the managed agent's status...".
- `FULL_PROFILE` (name="full"): All tools with default descriptions. No description overrides. IMPORTANT: `tool_configs` must explicitly map ALL 15 tool names to `ToolConfig(enabled=True)`. The `filter_tools()` method only includes tools present in `tool_configs`, so omitting a tool name would silently exclude it.

Also provide `get_profile(name: str) -> ToolProfile` function that returns the profile by name. Raises ValueError for unknown profiles.

**__init__.py** -- Re-export: ToolDefinition, ToolConfig, ToolProfile, ToolResult, ToolExecutor, get_all_tools, get_profile, SELF_PROFILE, SUPERVISOR_PROFILE, FULL_PROFILE. Also re-export `ToolCall` from `tract.orchestrator.models` for convenience (Plan 02 is the canonical owner).
  </action>
  <verify>
python -c "from tract.toolkit import ToolDefinition, ToolProfile, get_all_tools, get_profile, SELF_PROFILE, SUPERVISOR_PROFILE, FULL_PROFILE; print('imports OK')"
  </verify>
  <done>
All toolkit models importable. get_all_tools() returns 15 ToolDefinitions. Three built-in profiles exist with appropriate tool subsets and descriptions. to_openai() and to_anthropic() produce valid dicts.
  </done>
</task>

<task type="auto">
  <name>Task 2: ToolExecutor, Tract.as_tools() Facade, and Tests</name>
  <files>
    src/tract/toolkit/executor.py
    src/tract/tract.py
    src/tract/__init__.py
    tests/test_toolkit.py
  </files>
  <action>
**executor.py** -- `ToolExecutor` class:
```
class ToolExecutor:
    def __init__(self, tract: Tract) -> None:
        self._tract = tract
        self._tools: dict[str, ToolDefinition] = {}
        self._rebuild_tools()

    def _rebuild_tools(self) -> None:
        from tract.toolkit.definitions import get_all_tools
        for tool in get_all_tools(self._tract):
            self._tools[tool.name] = tool

    def execute(self, tool_name: str, arguments: dict) -> ToolResult:
        tool = self._tools.get(tool_name)
        if tool is None:
            return ToolResult(tool_name=tool_name, success=False, error=f"Unknown tool: {tool_name}")
        try:
            result = tool.handler(**arguments)
            return ToolResult(tool_name=tool_name, success=True, output=str(result))
        except Exception as exc:
            return ToolResult(tool_name=tool_name, success=False, error=f"{type(exc).__name__}: {exc}")

    def available_tools(self) -> list[str]:
        return list(self._tools.keys())
```

**Tract.as_tools()** -- Add method to `src/tract/tract.py`:
```python
def as_tools(
    self,
    *,
    profile: str | ToolProfile = "self",
    overrides: dict[str, str] | None = None,
    format: str = "openai",
) -> list[dict]:
```
Implementation: import from `tract.toolkit` (lazy, inside method body to avoid circular imports). Call `get_all_tools(self)`, apply profile filtering, apply overrides via `dataclasses.replace()`, convert to requested format. Return list of dicts.

**Tract.__init__.py** -- Add toolkit exports:
- `ToolDefinition`, `ToolProfile`, `ToolConfig`, `ToolResult`, `ToolExecutor` to imports and `__all__`. (ToolCall is exported from orchestrator package, added in Plan 03.)

**tests/test_toolkit.py** -- Comprehensive tests (~150+ lines):

1. `test_tool_definition_to_openai` -- Verify to_openai() produces correct dict structure
2. `test_tool_definition_to_anthropic` -- Verify to_anthropic() produces correct dict structure
3. `test_get_all_tools_returns_definitions` -- get_all_tools() returns 15 ToolDefinitions, all have name/description/parameters/handler
4. `test_self_profile_subset` -- SELF_PROFILE includes only expected tools (commit, compile, annotate, status, log, compress, branch, switch, reset)
5. `test_supervisor_profile_all_tools` -- SUPERVISOR_PROFILE includes all 15 tools
6. `test_full_profile_all_tools` -- FULL_PROFILE includes all 15 tools with default descriptions
7. `test_profile_description_overrides` -- Self profile descriptions contain "your" (self-referential)
8. `test_get_profile_by_name` -- get_profile("self"), get_profile("supervisor"), get_profile("full") all work
9. `test_get_profile_unknown_raises` -- get_profile("unknown") raises ValueError
10. `test_tool_executor_execute_status` -- ToolExecutor.execute("status", {}) returns ToolResult(success=True)
11. `test_tool_executor_execute_unknown` -- ToolExecutor.execute("nonexistent", {}) returns ToolResult(success=False, error="Unknown tool: nonexistent")
12. `test_tool_executor_execute_error` -- Execute with bad args returns ToolResult(success=False)
13. `test_as_tools_default_profile` -- Tract.as_tools() returns list of dicts (OpenAI format by default), count matches self profile
14. `test_as_tools_supervisor_profile` -- Tract.as_tools(profile="supervisor") returns all tools
15. `test_as_tools_anthropic_format` -- Tract.as_tools(format="anthropic") returns Anthropic-format dicts
16. `test_as_tools_with_overrides` -- Tract.as_tools(overrides={"status": "Custom desc"}) overrides description
17. `test_tool_executor_commit` -- Execute commit tool with DialogueContent, verify commit created
18. `test_tool_executor_compress` -- Execute compress tool (manual content), verify compression

Tests use real Tract instances opened with `Tract.open(str(tmp_path / "test.db"))` using `tmp_path` fixture. The first positional argument to `Tract.open()` is `path` (NOT `db_path`). Follow existing test patterns from `tests/test_tract.py`.
  </action>
  <verify>
python -m pytest tests/test_toolkit.py -v
  </verify>
  <done>
ToolExecutor dispatches tool calls correctly. Tract.as_tools() returns tool definition dicts in both OpenAI and Anthropic formats. Profile filtering works. All 18 tests pass. Full existing test suite still passes (798+ tests).
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_toolkit.py -v` -- all toolkit tests pass
2. `python -m pytest tests/ -x --timeout=120` -- full suite passes (no regressions)
3. `python -c "from tract import Tract, ToolDefinition, ToolProfile, ToolExecutor; t = Tract.open(); tools = t.as_tools(); print(f'{len(tools)} tools'); t.close()"` -- smoke test
</verification>

<success_criteria>
1. `Tract.as_tools()` returns tool definition dicts ready for LLM API consumption
2. Three built-in profiles (self, supervisor, full) curate appropriate tool subsets with scenario-appropriate descriptions
3. User can override descriptions on top of any profile
4. ToolExecutor dispatches tool call dicts to Tract methods and returns structured results
5. All tests pass with zero regressions
</success_criteria>

<output>
After completion, create `.planning/phases/07-agent-toolkit-orchestrator/07-01-SUMMARY.md`
</output>
