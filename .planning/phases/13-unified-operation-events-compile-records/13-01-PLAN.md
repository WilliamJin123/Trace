---
phase: 13-unified-operation-events-compile-records
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/tract/storage/schema.py
  - src/tract/storage/repositories.py
  - src/tract/storage/sqlite.py
  - src/tract/storage/engine.py
  - tests/test_compression_storage.py
autonomous: true

must_haves:
  truths:
    - "OperationEventRow + OperationCommitRow tables can be created and queried"
    - "CompileRecordRow + CompileEffectiveRow tables can be created and queried"
    - "OperationEventRow has indexed original_tokens and compressed_tokens columns"
    - "OperationEventRepository ABC and SqliteOperationEventRepository implementation exist and pass tests"
    - "CompileRecordRepository ABC and SqliteCompileRecordRepository implementation exist and pass tests"
    - "Schema version bumps from 5 to 6 with migration creating new tables and dropping old ones"
    - "CompressionRow, CompressionSourceRow, CompressionResultRow table definitions are removed from schema.py"
    - "CompressionRepository ABC and SqliteCompressionRepository are removed from repositories.py and sqlite.py"
  artifacts:
    - path: "src/tract/storage/schema.py"
      provides: "OperationEventRow, OperationCommitRow, CompileRecordRow, CompileEffectiveRow"
      contains: "class OperationEventRow"
    - path: "src/tract/storage/repositories.py"
      provides: "OperationEventRepository, CompileRecordRepository ABCs"
      contains: "class OperationEventRepository"
    - path: "src/tract/storage/sqlite.py"
      provides: "SqliteOperationEventRepository, SqliteCompileRecordRepository"
      contains: "class SqliteOperationEventRepository"
    - path: "src/tract/storage/engine.py"
      provides: "v5->v6 migration in init_db"
      contains: "existing.value == \"5\""
    - path: "tests/test_compression_storage.py"
      provides: "Tests for new repository implementations"
  key_links:
    - from: "src/tract/storage/sqlite.py"
      to: "src/tract/storage/schema.py"
      via: "ORM row imports"
    - from: "src/tract/storage/sqlite.py"
      to: "src/tract/storage/repositories.py"
      via: "ABC inheritance"
    - from: "src/tract/storage/engine.py"
      to: "src/tract/storage/schema.py"
      via: "Base.metadata.create_all + table drops"
---

<objective>
Create the new unified storage layer: 4 new schema tables (OperationEventRow, OperationCommitRow, CompileRecordRow, CompileEffectiveRow), 2 new repository ABCs and their SQLite implementations, schema v5->v6 migration, and rewritten storage-level tests. Simultaneously remove the 3 old compression tables and their repository interfaces.

Purpose: This is the foundation layer -- all subsequent plans depend on these tables and repositories existing.
Output: New schema tables, repository interfaces, SQLite implementations, migration logic, and passing storage tests.
</objective>

<execution_context>
@C:\Users\jinwi\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jinwi\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-unified-operation-events-compile-records/13-RESEARCH.md
@src/tract/storage/schema.py
@src/tract/storage/repositories.py
@src/tract/storage/sqlite.py
@src/tract/storage/engine.py
@tests/test_compression_storage.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: New schema tables + remove old tables + migration</name>
  <files>
    src/tract/storage/schema.py
    src/tract/storage/engine.py
  </files>
  <action>
**In `src/tract/storage/schema.py`:**

1. **Remove** the three old table classes: `CompressionRow`, `CompressionSourceRow`, `CompressionResultRow` (lines ~160-219).

2. **Add** four new table classes in the same location (after `CommitParentRow`, before `SpawnPointerRow`):

   a. `OperationEventRow`:
      - `__tablename__ = "operation_events"`
      - `event_id: Mapped[str] = mapped_column(String(64), primary_key=True)`
      - `tract_id: Mapped[str] = mapped_column(String(64), nullable=False, index=True)`
      - `event_type: Mapped[str] = mapped_column(String(30), nullable=False)` -- values: "compress", "reorganize", "import"
      - `branch_name: Mapped[Optional[str]] = mapped_column(String(255), nullable=True)`
      - `created_at: Mapped[datetime] = mapped_column(DateTime, nullable=False)`
      - `original_tokens: Mapped[int] = mapped_column(Integer, nullable=False, default=0)`
      - `compressed_tokens: Mapped[int] = mapped_column(Integer, nullable=False, default=0)`
      - `params_json: Mapped[Optional[dict]] = mapped_column(JSON, nullable=True)`
      - `__table_args__` with 3 indexes: composite (tract_id, event_type), original_tokens, compressed_tokens

   b. `OperationCommitRow`:
      - `__tablename__ = "operation_commits"`
      - Composite PK: event_id (FK -> operation_events.event_id), commit_hash (FK -> commits.commit_hash), role
      - `role: Mapped[str] = mapped_column(String(10), primary_key=True)` -- "source" or "result"
      - `position: Mapped[int] = mapped_column(Integer, nullable=False)`
      - `__table_args__` with 2 indexes: event_id, (commit_hash, role)

   c. `CompileRecordRow`:
      - `__tablename__ = "compile_records"`
      - `record_id: Mapped[str] = mapped_column(String(64), primary_key=True)`
      - `tract_id: Mapped[str] = mapped_column(String(64), nullable=False, index=True)`
      - `head_hash: Mapped[str] = mapped_column(String(64), nullable=False)`
      - `token_count: Mapped[int] = mapped_column(Integer, nullable=False)`
      - `commit_count: Mapped[int] = mapped_column(Integer, nullable=False)`
      - `token_source: Mapped[str] = mapped_column(String(50), nullable=False)`
      - `params_json: Mapped[Optional[dict]] = mapped_column(JSON, nullable=True)`
      - `created_at: Mapped[datetime] = mapped_column(DateTime, nullable=False)`
      - `__table_args__` with 1 index: (tract_id, created_at)

   d. `CompileEffectiveRow`:
      - `__tablename__ = "compile_effectives"`
      - Composite PK: record_id (FK -> compile_records.record_id), commit_hash (FK -> commits.commit_hash)
      - `position: Mapped[int] = mapped_column(Integer, nullable=False)`

3. Follow exact patterns from 13-RESEARCH.md code examples.

**In `src/tract/storage/engine.py`:**

4. Update `init_db()`:
   - Change new database version from "5" to "6"
   - Add v5->v6 migration block after the v4->v5 block:
     ```python
     if existing is not None and existing.value == "5":
         # Migrate v5 -> v6: unified operation events + compile records
         # Create new tables
         for table_name in ["operation_events", "operation_commits",
                            "compile_records", "compile_effectives"]:
             Base.metadata.tables[table_name].create(engine, checkfirst=True)
         # Migrate existing compression data to operation_events
         _migrate_compressions_v5_to_v6(engine)
         # Drop old compression tables (order matters: children first)
         from sqlalchemy import text
         with engine.connect() as conn:
             conn.execute(text("DROP TABLE IF EXISTS compression_results"))
             conn.execute(text("DROP TABLE IF EXISTS compression_sources"))
             conn.execute(text("DROP TABLE IF EXISTS compressions"))
             conn.commit()
         existing.value = "6"
         session.commit()
     ```
   - Add a `_migrate_compressions_v5_to_v6(engine)` helper function that:
     - Opens a connection, reads all rows from `compressions` table
     - For each row, inserts into `operation_events` with `event_type="compress"`, mapping `compression_id -> event_id`, `target_tokens -> params_json.target_tokens`, `instructions -> params_json.instructions`
     - Reads `compression_sources` and `compression_results`, inserts into `operation_commits` with role="source" and role="result" respectively
     - Uses `text()` for raw SQL to avoid dependency on removed ORM classes
   - **Update the v2->v3 migration block** to use raw SQL instead of `Base.metadata.tables[...]` (since CompressionRow/CompressionSourceRow/CompressionResultRow ORM classes are removed and those table names will no longer exist in Base.metadata). Replace the three `Base.metadata.tables[...].create(...)` calls with:
     ```python
     from sqlalchemy import text
     with engine.connect() as conn:
         conn.execute(text("""
             CREATE TABLE IF NOT EXISTS compressions (
                 compression_id VARCHAR(64) PRIMARY KEY,
                 tract_id VARCHAR(64) NOT NULL,
                 branch_name VARCHAR(255),
                 target_tokens INTEGER,
                 instructions TEXT,
                 created_at DATETIME NOT NULL
             )
         """))
         conn.execute(text("""
             CREATE TABLE IF NOT EXISTS compression_sources (
                 compression_id VARCHAR(64) NOT NULL REFERENCES compressions(compression_id),
                 commit_hash VARCHAR(64) NOT NULL REFERENCES commits(commit_hash),
                 position INTEGER NOT NULL,
                 PRIMARY KEY (compression_id, commit_hash)
             )
         """))
         conn.execute(text("""
             CREATE TABLE IF NOT EXISTS compression_results (
                 compression_id VARCHAR(64) NOT NULL REFERENCES compressions(compression_id),
                 commit_hash VARCHAR(64) NOT NULL REFERENCES commits(commit_hash),
                 position INTEGER NOT NULL,
                 PRIMARY KEY (compression_id, commit_hash)
             )
         """))
         conn.commit()
     ```
     This ensures the v2->v3->v4->v5->v6 migration chain still works end-to-end, even though the ORM classes no longer exist. The v5->v6 migration will subsequently drop these tables.
  </action>
  <verify>
    Run: `python -c "from tract.storage.schema import OperationEventRow, OperationCommitRow, CompileRecordRow, CompileEffectiveRow; print('OK')"` -- must print OK.
    Run: `python -c "from tract.storage.engine import init_db, create_trace_engine; e = create_trace_engine(); init_db(e); print('OK')"` -- must print OK.
    Verify: `grep -c "CompressionRow\|CompressionSourceRow\|CompressionResultRow" src/tract/storage/schema.py` returns 0.
    Run: `python -c "
from sqlalchemy import create_engine, text
from tract.storage.engine import init_db

# Test v2->v6 migration: create a v2 DB with old tables, then init_db() should migrate to v6
e = create_engine('sqlite://')
with e.connect() as c:
    c.execute(text('CREATE TABLE _trace_meta (key VARCHAR PRIMARY KEY, value VARCHAR)'))
    c.execute(text(\"INSERT INTO _trace_meta VALUES ('schema_version', '2')\"))
    c.execute(text('CREATE TABLE blobs (blob_hash VARCHAR(64) PRIMARY KEY, content_type VARCHAR(30), body TEXT, token_count INTEGER, encoding VARCHAR(30), tract_id VARCHAR(64))'))
    c.execute(text('CREATE TABLE commits (commit_hash VARCHAR(64) PRIMARY KEY, tract_id VARCHAR(64), parent_hash VARCHAR(64), branch_name VARCHAR(255), operation VARCHAR(10), priority VARCHAR(10), edit_target VARCHAR(64), created_at DATETIME, blob_hash VARCHAR(64) REFERENCES blobs(blob_hash), generation_config_json TEXT)'))
    c.execute(text('CREATE TABLE commit_parents (commit_hash VARCHAR(64), parent_hash VARCHAR(64), position INTEGER, PRIMARY KEY (commit_hash, parent_hash))'))
    c.commit()
init_db(e)
with e.connect() as c:
    v = c.execute(text(\"SELECT value FROM _trace_meta WHERE key='schema_version'\")).scalar()
    assert v == '6', f'Expected v6 but got v{v}'
    # Verify new tables exist
    tables = [r[0] for r in c.execute(text(\"SELECT name FROM sqlite_master WHERE type='table'\")).fetchall()]
    assert 'operation_events' in tables, 'operation_events missing'
    assert 'compile_records' in tables, 'compile_records missing'
    # Verify old compression tables are dropped
    assert 'compressions' not in tables, 'compressions should be dropped'
print('v2->v6 migration OK')
"` -- must print "v2->v6 migration OK".
  </verify>
  <done>
    4 new table classes defined in schema.py with correct columns, FKs, and indexes. 3 old table classes removed. init_db() creates schema v6 for new DBs and migrates v5->v6 with data migration and old table drops. Old v2->v3 migration path still works (using raw SQL for removed tables).
  </done>
</task>

<task type="auto">
  <name>Task 2: Repository interfaces + SQLite implementations + tests</name>
  <files>
    src/tract/storage/repositories.py
    src/tract/storage/sqlite.py
    tests/test_compression_storage.py
  </files>
  <action>
**In `src/tract/storage/repositories.py`:**

1. **Remove** the entire `CompressionRepository` ABC class (~lines 279-357).

2. **Remove** `CompressionRow`, `CompressionSourceRow`, `CompressionResultRow` from the TYPE_CHECKING imports block.

3. **Add** to TYPE_CHECKING imports: `OperationEventRow`, `OperationCommitRow`, `CompileRecordRow`, `CompileEffectiveRow`.

4. **Add** `OperationEventRepository` ABC with these abstract methods:
   - `save_event(self, event_id: str, tract_id: str, event_type: str, branch_name: str | None, created_at: datetime, original_tokens: int, compressed_tokens: int, params_json: dict | None) -> None`
   - `add_commit(self, event_id: str, commit_hash: str, role: str, position: int) -> None`
   - `get_event(self, event_id: str) -> OperationEventRow | None`
   - `get_commits(self, event_id: str, role: str | None = None) -> list[OperationCommitRow]`
   - `is_source_of(self, commit_hash: str) -> bool` -- check if commit is source in any event
   - `get_all_source_hashes(self, tract_id: str) -> set[str]` -- all source hashes for a tract
   - `get_all_ids(self, tract_id: str) -> list[str]` -- all event IDs for a tract
   - `delete_commit(self, commit_hash: str) -> None` -- delete all OperationCommitRow entries for a hash
   - `delete_event(self, event_id: str) -> None` -- delete event and all its commit associations

5. **Add** `CompileRecordRepository` ABC with these abstract methods:
   - `save_record(self, record_id: str, tract_id: str, head_hash: str, token_count: int, commit_count: int, token_source: str, params_json: dict | None, created_at: datetime) -> None`
   - `add_effective(self, record_id: str, commit_hash: str, position: int) -> None`
   - `get_record(self, record_id: str) -> CompileRecordRow | None`
   - `get_all(self, tract_id: str) -> list[CompileRecordRow]`
   - `get_effectives(self, record_id: str) -> list[CompileEffectiveRow]`

**In `src/tract/storage/sqlite.py`:**

6. **Remove** the entire `SqliteCompressionRepository` class (~lines 589-727).

7. **Remove** `CompressionRow`, `CompressionSourceRow`, `CompressionResultRow` from imports. Remove `CompressionRepository` from imports.

8. **Add** imports: `OperationEventRow`, `OperationCommitRow`, `CompileRecordRow`, `CompileEffectiveRow` from schema. `OperationEventRepository`, `CompileRecordRepository` from repositories.

9. **Add** `SqliteOperationEventRepository(OperationEventRepository)`:
   - `__init__(self, session: Session)` -- stores self._session
   - Implement all 9 ABC methods following the exact patterns from SqliteCompressionRepository:
     - `save_event`: create OperationEventRow, add, flush
     - `add_commit`: create OperationCommitRow, add, flush
     - `get_event`: select where event_id
     - `get_commits`: select where event_id, optional role filter, order by position
     - `is_source_of`: select OperationCommitRow where commit_hash and role="source", return first is not None
     - `get_all_source_hashes`: join OperationCommitRow with OperationEventRow on event_id, filter tract_id and role="source"
     - `get_all_ids`: select event_id where tract_id
     - `delete_commit`: delete all OperationCommitRow entries for commit_hash
     - `delete_event`: delete commit rows first, then event row

10. **Add** `SqliteCompileRecordRepository(CompileRecordRepository)`:
    - `__init__(self, session: Session)` -- stores self._session
    - Implement all 5 ABC methods:
      - `save_record`: create CompileRecordRow, add, flush
      - `add_effective`: create CompileEffectiveRow, add, flush
      - `get_record`: select where record_id
      - `get_all`: select where tract_id, order by created_at
      - `get_effectives`: select where record_id, order by position

**In `tests/test_compression_storage.py`:**

11. **Completely rewrite** this file. The old file tests CompressionRow/Source/Result. Replace with tests for OperationEventRow/OperationCommitRow and CompileRecordRow/CompileEffectiveRow.

    Test structure (follow existing test patterns in the project):
    - Fixture: `db_session` that creates engine, init_db, yields session
    - Fixture: `event_repo` returning SqliteOperationEventRepository(session)
    - Fixture: `compile_record_repo` returning SqliteCompileRecordRepository(session)
    - Fixture: helper to create commits (need BlobRow + CommitRow in DB for FK constraints)

    Test cases for OperationEventRepository:
    - `test_save_and_get_event` -- save, get, verify all fields
    - `test_add_and_get_commits` -- add source/result commits, get by event_id, get by role
    - `test_is_source_of` -- True for source commits, False for result and unknown
    - `test_get_all_source_hashes` -- multiple events, verify union of sources
    - `test_get_all_ids` -- multiple events, verify list
    - `test_delete_commit` -- delete source, verify removed
    - `test_delete_event` -- delete event, verify event and all commits removed
    - `test_event_types` -- "compress", "reorganize", "import" all work
    - `test_indexed_token_columns` -- original_tokens and compressed_tokens stored and queryable
    - `test_params_json_roundtrip` -- JSON params survive save/load

    Test cases for CompileRecordRepository:
    - `test_save_and_get_record` -- save, get, verify all fields
    - `test_add_and_get_effectives` -- add effectives, get, verify order
    - `test_get_all` -- multiple records, verify chronological order
    - `test_params_json_roundtrip` -- JSON params survive save/load

    Test cases for schema migration:
    - `test_init_db_creates_v6` -- new DB has version "6"
    - `test_operation_event_table_exists` -- inspector shows table
    - `test_compile_record_table_exists` -- inspector shows table
    - `test_migrate_v2_to_v6` -- create a DB at schema v2 with old commit/blob tables via raw SQL, call init_db(), verify schema_version reaches "6", new tables (operation_events, compile_records) exist, and old tables (compressions, compression_sources, compression_results) are dropped
    - `test_migrate_v5_to_v6` -- create a DB at schema v5 with old compression tables populated via raw SQL, call init_db(), verify schema_version reaches "6", data migrated to operation_events/operation_commits, old tables dropped
  </action>
  <verify>
    Run: `python -m pytest tests/test_compression_storage.py -v` -- all tests pass.
    Run: `python -c "from tract.storage.sqlite import SqliteOperationEventRepository, SqliteCompileRecordRepository; print('OK')"` -- prints OK.
    Run: `python -c "from tract.storage.repositories import OperationEventRepository, CompileRecordRepository; print('OK')"` -- prints OK.
    Verify: `grep -c "CompressionRepository\|SqliteCompressionRepository\|CompressionRow\|CompressionSourceRow\|CompressionResultRow" src/tract/storage/repositories.py src/tract/storage/sqlite.py` returns 0 for both files.
  </verify>
  <done>
    CompressionRepository ABC and SqliteCompressionRepository removed. OperationEventRepository + CompileRecordRepository ABCs defined with all abstract methods. SqliteOperationEventRepository + SqliteCompileRecordRepository implemented following existing codebase patterns. test_compression_storage.py fully rewritten with ~20 test cases covering all repository methods, schema migration, and edge cases. All tests pass.
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_compression_storage.py -v` -- ALL tests pass
2. `python -c "from tract.storage.schema import OperationEventRow, OperationCommitRow, CompileRecordRow, CompileEffectiveRow"` -- no import errors
3. `python -c "from tract.storage.sqlite import SqliteOperationEventRepository, SqliteCompileRecordRepository"` -- no import errors
4. `python -c "from tract.storage.engine import init_db, create_trace_engine; e = create_trace_engine(); init_db(e)"` -- no errors
5. `grep -r "CompressionRow\|CompressionSourceRow\|CompressionResultRow\|CompressionRepository\|SqliteCompressionRepository" src/tract/storage/` returns ZERO matches
6. Schema version for new databases is "6"
</verification>

<success_criteria>
1. Four new ORM table classes exist in schema.py with correct columns, FKs, indexes
2. OperationEventRow has indexed original_tokens and compressed_tokens columns (SC-6)
3. Two new repository ABCs and two SQLite implementations exist
4. Old compression tables (3 classes) and repositories (2 classes) are fully removed from storage layer
5. init_db() handles v5->v6 migration (create new tables, migrate data, drop old tables)
6. All storage-level tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/13-unified-operation-events-compile-records/13-01-SUMMARY.md`
</output>
