---
phase: 01.4-lru-compile-cache-snapshot-patching
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/tract/engine/compiler.py
  - src/tract/protocols.py
  - src/tract/models/compiled.py
  - src/tract/models/config.py
  - src/tract/tract.py
  - tests/test_engine/test_compiler.py
  - tests/test_tract.py
autonomous: true

must_haves:
  truths:
    - "Same-role consecutive messages are preserved as separate messages in compiled output; _aggregate_messages() is removed entirely"
    - "CompileSnapshot has `messages` and `commit_hashes` fields that are always parallel (same length, same indexing); `raw_messages`, `aggregated_messages`, and `effective_hashes` are removed"
    - "CompiledContext includes `commit_hashes: list[str]` listing effective commit hashes in message order, populated by the compiler"
    - "Multiple compile snapshots cached simultaneously via LRU; switching HEAD to a previously-compiled position is a cache hit (O(1))"
    - "Incremental APPEND extends cached snapshot with new message and commit hash in O(1), no tail aggregation"
    - "EDIT commits patch cached snapshot in-memory: find message by commit hash, replace, recount tokens -- no chain re-walk, no re-aggregation"
    - "Annotate SKIP patches cached snapshot by removing target message; un-skip falls back to full recompile; entire cache cleared on annotation (other HEAD entries are stale), then patched current HEAD re-added"
    - "batch() clears entire LRU cache; crash loses cache; DB is always source of truth"
    - "verify_cache=True on Tract.open() cross-checks every cache hit/patch against a full recompile"
    - "Copy-on-input for generation_config dicts in all snapshot construction (patching, extend, build)"
  artifacts:
    - path: "src/tract/protocols.py"
      provides: "Simplified CompileSnapshot with messages/commit_hashes; CompiledContext with commit_hashes"
      contains: "commit_hashes"
    - path: "src/tract/engine/compiler.py"
      provides: "No _aggregate_messages; compile() populates commit_hashes"
      contains: "commit_hashes"
    - path: "src/tract/tract.py"
      provides: "LRU cache, EDIT patching, annotate patching, verify_cache"
      contains: "_snapshot_cache"
    - path: "tests/test_tract.py"
      provides: "Tests for no-aggregation, LRU, EDIT patching, annotate patching, oracle verification"
      min_lines: 30
  key_links:
    - from: "src/tract/tract.py"
      to: "src/tract/protocols.py"
      via: "CompileSnapshot.commit_hashes for EDIT patching lookup"
      pattern: "snapshot\\.commit_hashes"
    - from: "src/tract/tract.py"
      to: "src/tract/engine/compiler.py"
      via: "build_message_for_commit() reused for EDIT patching"
      pattern: "build_message_for_commit"
    - from: "src/tract/tract.py"
      to: "collections.OrderedDict"
      via: "LRU cache backing store"
      pattern: "OrderedDict"
---

<objective>
Two changes in one phase:

1. **Remove same-role message aggregation** from the compilation pipeline. Commits are discrete events (user message, tool result, instruction). Aggregation destroys event boundaries and makes commit-to-message mapping impossible. Without aggregation, `messages` and `commit_hashes` are trivially parallel (one message per effective commit, always).

2. **Replace single-snapshot compile cache with LRU + snapshot patching.** LRU cache keyed by head_hash gives cache hits on checkout/reset/branch-switch. EDIT commits patch the cached snapshot in-memory instead of invalidating. Annotate SKIP removes the target message from the snapshot. No re-aggregation needed anywhere.

These changes are synergistic: removing aggregation eliminates the `raw_messages`/`aggregated_messages` split on CompileSnapshot, which was the root cause of the `commit_hashes` parallelism bug that would have made EDIT patching incorrect.

Output: Modified compiler.py (no aggregation, populates commit_hashes), simplified protocols.py (CompileSnapshot/CompiledContext), removed aggregate_same_role from compiled.py, added compile_cache_maxsize to config.py, LRU cache + patching in tract.py, updated tests.
</objective>

<execution_context>
@C:\Users\jinwi\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\jinwi\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01.4-lru-compile-cache-snapshot-patching/01.4-RESEARCH.md
@.planning/phases/01.1-compile-cache-token-tracking/01.1-01-SUMMARY.md
@.planning/phases/01.3-hyperparameter-config-storage/01.3-01-SUMMARY.md
@src/tract/protocols.py
@src/tract/tract.py
@src/tract/engine/compiler.py
@src/tract/models/compiled.py
@src/tract/models/config.py
@tests/test_tract.py
@tests/test_engine/test_compiler.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Remove same-role aggregation and simplify data model</name>
  <files>
    src/tract/engine/compiler.py
    src/tract/protocols.py
    src/tract/models/compiled.py
    src/tract/tract.py
    tests/test_engine/test_compiler.py
    tests/test_tract.py
  </files>
  <action>
**1. Remove `_aggregate_messages()` from `src/tract/engine/compiler.py`:**

Delete the entire `_aggregate_messages` method (lines 350-372). Then in `compile()`, remove the call to it. Currently:

```python
# Step 7: Aggregate same-role consecutive messages
messages = self._aggregate_messages(messages)
```

Delete these two lines. The `messages` from `_build_messages()` go directly to token counting.

**2. Add `commit_hashes` to the return value in `compiler.compile()`:**

After building `effective_commits` (step 4), extract commit hashes:

```python
effective_commit_hashes = [c.commit_hash for c in effective_commits]
```

Add this to the return:

```python
return CompiledContext(
    messages=messages,
    token_count=token_count,
    commit_count=len(effective_commits),
    token_source=token_source,
    generation_configs=generation_configs,
    commit_hashes=effective_commit_hashes,
)
```

**3. Add `commit_hashes` field to `CompiledContext` in `src/tract/protocols.py`:**

```python
@dataclass(frozen=True)
class CompiledContext:
    messages: list[Message] = field(default_factory=list)
    token_count: int = 0
    commit_count: int = 0
    token_source: str = ""
    generation_configs: list[dict] = field(default_factory=list)
    commit_hashes: list[str] = field(default_factory=list)  # NEW
```

**4. Simplify `CompileSnapshot` in `src/tract/protocols.py`:**

Replace `raw_messages`, `aggregated_messages`, and `effective_hashes` with `messages` and `commit_hashes`:

```python
@dataclass(frozen=True)
class CompileSnapshot:
    """Cached intermediate compilation state for incremental extension.

    Each position in `messages` corresponds to one effective commit.
    `commit_hashes[i]` is the commit that produced `messages[i]`.
    """

    head_hash: str
    messages: tuple[Message, ...]
    commit_count: int
    token_count: int
    token_source: str
    generation_configs: tuple[dict, ...] = ()
    commit_hashes: tuple[str, ...] = ()
```

**5. Remove `aggregate_same_role` from `CompileOptions` in `src/tract/models/compiled.py`:**

Delete the `aggregate_same_role: bool = True` field and its docstring entirely.

**6. Update `_snapshot_to_compiled()` in `src/tract/tract.py`:**

```python
def _snapshot_to_compiled(self, snapshot: CompileSnapshot) -> CompiledContext:
    return CompiledContext(
        messages=list(snapshot.messages),
        token_count=snapshot.token_count,
        commit_count=snapshot.commit_count,
        token_source=snapshot.token_source,
        generation_configs=[dict(c) for c in snapshot.generation_configs],
        commit_hashes=list(snapshot.commit_hashes),
    )
```

**7. Update `_build_snapshot_from_compiled()` in `src/tract/tract.py`:**

```python
def _build_snapshot_from_compiled(
    self, head_hash: str, result: CompiledContext
) -> CompileSnapshot | None:
    if not isinstance(self._compiler, DefaultContextCompiler):
        return None
    return CompileSnapshot(
        head_hash=head_hash,
        messages=tuple(result.messages),
        commit_count=result.commit_count,
        token_count=result.token_count,
        token_source=result.token_source,
        generation_configs=tuple(dict(c) for c in result.generation_configs),
        commit_hashes=tuple(result.commit_hashes),
    )
```

Note: `result.messages` and `result.commit_hashes` are now guaranteed parallel (both length N, one per effective commit) because aggregation is removed. No duplicate chain walk needed.

**8. Simplify `_extend_snapshot_for_append()` in `src/tract/tract.py`:**

Remove all tail aggregation logic. The method becomes:

```python
def _extend_snapshot_for_append(self, commit_info: CommitInfo) -> None:
    snapshot = self._compile_snapshot
    if snapshot is None:
        return

    commit_row = self._commit_repo.get(commit_info.commit_hash)
    if commit_row is None:
        self._compile_snapshot = None
        return

    assert isinstance(self._compiler, DefaultContextCompiler)
    new_message = self._compiler.build_message_for_commit(commit_row)
    new_config = dict(commit_row.generation_config_json or {})

    new_messages = snapshot.messages + (new_message,)
    new_commit_hashes = snapshot.commit_hashes + (commit_info.commit_hash,)

    # Recount tokens on all messages
    messages_dicts = [
        {"role": m.role, "content": m.content}
        if m.name is None
        else {"role": m.role, "content": m.content, "name": m.name}
        for m in new_messages
    ]
    new_token_count = self._token_counter.count_messages(messages_dicts)

    self._compile_snapshot = CompileSnapshot(
        head_hash=commit_info.commit_hash,
        messages=new_messages,
        commit_count=snapshot.commit_count + 1,
        token_count=new_token_count,
        token_source=self._tiktoken_source(),
        generation_configs=snapshot.generation_configs + (new_config,),
        commit_hashes=new_commit_hashes,
    )
```

**9. Update `record_usage()` in `src/tract/tract.py`:**

Replace all references to `raw_messages` and `aggregated_messages` with `messages`. The snapshot construction becomes:

```python
self._compile_snapshot = CompileSnapshot(
    head_hash=self._compile_snapshot.head_hash,
    messages=self._compile_snapshot.messages,
    commit_count=self._compile_snapshot.commit_count,
    token_count=usage.prompt_tokens,
    token_source=token_source,
    generation_configs=self._compile_snapshot.generation_configs,
    commit_hashes=self._compile_snapshot.commit_hashes,
)
```

**10. Update tests in `tests/test_engine/test_compiler.py`:**

Replace the `TestAggregation` class (lines 371-413) with `TestNoAggregation`:

```python
class TestNoAggregation:
    """Consecutive same-role messages remain separate (no aggregation)."""

    def test_consecutive_same_role_separate(self, commit_engine, compiler) -> None:
        """Two consecutive user messages remain as two separate messages."""
        commit_engine.create_commit(DialogueContent(role="user", text="Part 1"))
        c2 = commit_engine.create_commit(DialogueContent(role="user", text="Part 2"))

        result = compiler.compile(TRACT_ID, c2.commit_hash)

        assert len(result.messages) == 2
        assert result.messages[0].content == "Part 1"
        assert result.messages[1].content == "Part 2"
        assert result.messages[0].role == "user"
        assert result.messages[1].role == "user"

    def test_different_roles_separate(self, commit_engine, compiler) -> None:
        """Messages with different roles remain separate."""
        commit_engine.create_commit(DialogueContent(role="user", text="Hello"))
        c2 = commit_engine.create_commit(DialogueContent(role="assistant", text="Hi"))

        result = compiler.compile(TRACT_ID, c2.commit_hash)

        assert len(result.messages) == 2
        assert result.messages[0].role == "user"
        assert result.messages[1].role == "assistant"

    def test_mixed_roles_all_preserved(self, commit_engine, compiler) -> None:
        """user-user-assistant-user produces 4 messages, not 3."""
        commit_engine.create_commit(DialogueContent(role="user", text="A"))
        commit_engine.create_commit(DialogueContent(role="user", text="B"))
        commit_engine.create_commit(DialogueContent(role="assistant", text="C"))
        c4 = commit_engine.create_commit(DialogueContent(role="user", text="D"))

        result = compiler.compile(TRACT_ID, c4.commit_hash)

        assert len(result.messages) == 4
        assert result.messages[0].content == "A"
        assert result.messages[1].content == "B"
        assert result.messages[2].content == "C"
        assert result.messages[3].content == "D"

    def test_commit_hashes_parallel_to_messages(self, commit_engine, compiler) -> None:
        """CompiledContext.commit_hashes is parallel to messages."""
        c1 = commit_engine.create_commit(DialogueContent(role="user", text="A"))
        c2 = commit_engine.create_commit(DialogueContent(role="user", text="B"))
        c3 = commit_engine.create_commit(DialogueContent(role="assistant", text="C"))

        result = compiler.compile(TRACT_ID, c3.commit_hash)

        assert len(result.commit_hashes) == len(result.messages)
        assert result.commit_hashes[0] == c1.commit_hash
        assert result.commit_hashes[1] == c2.commit_hash
        assert result.commit_hashes[2] == c3.commit_hash
```

**11. Update tests in `tests/test_tract.py`:**

11a. `test_compile_aggregation` (line 403) -- rename and fix assertions:

```python
def test_compile_consecutive_same_role_separate(self, tract: Tract):
    """Consecutive same-role messages are preserved as separate messages."""
    tract.commit(DialogueContent(role="user", text="Part 1"))
    tract.commit(DialogueContent(role="user", text="Part 2"))
    result = tract.compile()
    assert len(result.messages) == 2
    assert result.messages[0].content == "Part 1"
    assert result.messages[1].content == "Part 2"
```

11b. `test_append_same_role_aggregation` (line 648) -- rename and fix assertions:

```python
def test_append_same_role_no_aggregation(self):
    """Incremental extend preserves consecutive same-role messages as separate."""
    with Tract.open(":memory:", tract_id="no-agg-test") as t:
        t.commit(DialogueContent(role="user", text="Part 1"))
        r1 = t.compile()
        assert len(r1.messages) == 1

        t.commit(DialogueContent(role="user", text="Part 2"))
        r2 = t.compile()
        assert len(r2.messages) == 2
        assert r2.messages[0].content == "Part 1"
        assert r2.messages[1].content == "Part 2"

        t.commit(DialogueContent(role="user", text="Part 3"))
        r3 = t.compile()
        assert len(r3.messages) == 3

    # Verify equivalence with full compile
    with Tract.open(":memory:", tract_id="no-agg-full") as t2:
        t2.commit(DialogueContent(role="user", text="Part 1"))
        t2.commit(DialogueContent(role="user", text="Part 2"))
        t2.commit(DialogueContent(role="user", text="Part 3"))
        full_result = t2.compile()

    assert len(r3.messages) == len(full_result.messages)
    assert r3.token_count == full_result.token_count
    assert r3.commit_count == full_result.commit_count
```

11c. Batch test (line 737) -- fix the assertion:

```python
assert len(result.messages) == 4  # system + 3 batch commits, no aggregation
```
  </action>
  <verify>
Run `cd "C:\Users\jinwi\programming_files_NEW\Trace" && .venv/Scripts/python -m pytest tests/ -x -q` -- all 250 existing tests must pass (with the updated aggregation tests). No regressions.
  </verify>
  <done>
- `_aggregate_messages()` removed from DefaultContextCompiler
- `aggregate_same_role` removed from CompileOptions
- CompileSnapshot simplified: `messages` + `commit_hashes` (parallel, no raw/aggregated split)
- `CompiledContext.commit_hashes` populated by compiler
- `_extend_snapshot_for_append` has no tail aggregation
- All aggregation tests updated to assert separate messages
- All 250 tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: LRU cache infrastructure</name>
  <files>
    src/tract/models/config.py
    src/tract/tract.py
  </files>
  <action>
**1. Add `compile_cache_maxsize` to TractConfig in `src/tract/models/config.py`:**

Add `compile_cache_maxsize: int = 8` after `default_branch`:

```python
class TractConfig(BaseModel):
    model_config = {"arbitrary_types_allowed": True}

    db_path: str = ":memory:"
    tokenizer_encoding: str = "o200k_base"
    token_budget: Optional[TokenBudgetConfig] = None
    default_branch: str = "main"
    compile_cache_maxsize: int = 8
```

**2. Add imports to `src/tract/tract.py`:**

Add `from collections import OrderedDict` and `from dataclasses import replace` at the top.

**3. Replace single snapshot with LRU cache in `__init__()`:**

Remove:
```python
self._compile_snapshot: CompileSnapshot | None = None
```

Add:
```python
self._snapshot_cache: OrderedDict[str, CompileSnapshot] = OrderedDict()
self._snapshot_cache_maxsize: int = config.compile_cache_maxsize
self._verify_cache: bool = False
```

**4. Add `verify_cache` parameter to `Tract.open()` and `Tract.from_components()`:**

Add `verify_cache: bool = False` parameter to both classmethods. Pass it through to `__init__` by adding a `verify_cache: bool = False` parameter to `__init__()` and storing as `self._verify_cache = verify_cache`.

In `Tract.open()`, add the parameter and pass `verify_cache=verify_cache` to `cls(...)`.
In `Tract.from_components()`, same.

**5. Add three private LRU cache helper methods:**

```python
def _cache_get(self, head_hash: str) -> CompileSnapshot | None:
    """Get snapshot from LRU cache. Returns None on miss."""
    if head_hash not in self._snapshot_cache:
        return None
    self._snapshot_cache.move_to_end(head_hash)
    return self._snapshot_cache[head_hash]

def _cache_put(self, head_hash: str, snapshot: CompileSnapshot) -> None:
    """Store snapshot in LRU cache, evicting LRU entry if at capacity."""
    if head_hash in self._snapshot_cache:
        self._snapshot_cache.move_to_end(head_hash)
    self._snapshot_cache[head_hash] = snapshot
    while len(self._snapshot_cache) > self._snapshot_cache_maxsize:
        self._snapshot_cache.popitem(last=False)

def _cache_clear(self) -> None:
    """Clear all cached snapshots."""
    self._snapshot_cache.clear()
```

**6. Update `compile()`:**

Replace the cache hit check:
```python
# OLD:
if self._compile_snapshot is not None and self._compile_snapshot.head_hash == current_head:
    return self._snapshot_to_compiled(self._compile_snapshot)
```

With:
```python
# NEW:
cached = self._cache_get(current_head)
if cached is not None:
    result = self._snapshot_to_compiled(cached)
    if self._verify_cache:
        fresh = self._compiler.compile(self._tract_id, current_head)
        assert result.messages == fresh.messages, (
            f"Cache message mismatch: cached {len(result.messages)} msgs, "
            f"fresh {len(fresh.messages)} msgs"
        )
        assert result.token_count == fresh.token_count, (
            f"Cache token mismatch: cached {result.token_count}, "
            f"fresh {fresh.token_count}"
        )
    return result
```

Replace the cache miss:
```python
# OLD:
self._compile_snapshot = self._build_snapshot_from_compiled(current_head, result)

# NEW:
snapshot = self._build_snapshot_from_compiled(current_head, result)
if snapshot is not None:
    self._cache_put(current_head, snapshot)
```

**7. Update `commit()` for APPEND path:**

Capture `prev_head` before the session commit. Change the APPEND path to use LRU:

```python
# Before self._session.commit():
prev_head = self.head

# After self._session.commit():
if (
    operation == CommitOperation.APPEND
    and isinstance(self._compiler, DefaultContextCompiler)
):
    parent_snapshot = self._cache_get(prev_head) if prev_head else None
    if parent_snapshot is not None:
        self._extend_snapshot_for_append(info, parent_snapshot)
    # If no parent snapshot, next compile() builds from scratch
else:
    # EDIT path: handled by Task 3 (for now, do nothing -- next compile() rebuilds)
    pass
```

Note: Do NOT call `self._cache_clear()` for EDIT. Other LRU entries at different HEAD positions are still valid (the EDIT commit is a new commit not in their chains).

**8. Update `_extend_snapshot_for_append()` signature:**

Change to accept `parent_snapshot` parameter instead of reading `self._compile_snapshot`:

```python
def _extend_snapshot_for_append(self, commit_info: CommitInfo, parent_snapshot: CompileSnapshot) -> None:
```

Replace `snapshot = self._compile_snapshot` with using the `parent_snapshot` parameter.
Replace `self._compile_snapshot = None` (the bail-out) with just `return`.
Replace `self._compile_snapshot = CompileSnapshot(...)` with `self._cache_put(commit_info.commit_hash, CompileSnapshot(...))`.

The parent snapshot stays in the LRU cache under `prev_head` (useful for future checkout back).

**9. Update `annotate()`:**

Replace `self._compile_snapshot = None` with `self._cache_clear()`.
(Task 3 will upgrade this to patching.)

**10. Update `batch()`:**

Replace `self._compile_snapshot = None` (on batch entry) with `self._cache_clear()`.

**11. Update `record_usage()`:**

Replace all `self._compile_snapshot` references with LRU cache lookups. Use `dataclasses.replace()`:

```python
# Replace the "If no snapshot yet" check:
snapshot = self._cache_get(target_hash)
if snapshot is None:
    self.compile()
    snapshot = self._cache_get(target_hash)

# Replace the snapshot update block:
if snapshot is not None:
    token_source = f"api:{usage.prompt_tokens}+{usage.completion_tokens}"
    updated = replace(snapshot, token_count=usage.prompt_tokens, token_source=token_source)
    self._cache_put(target_hash, updated)
    return self._snapshot_to_compiled(updated)
```

**IMPORTANT: After these changes, `self._compile_snapshot` must not appear anywhere in tract.py. All snapshot access goes through `_cache_get`/`_cache_put`/`_cache_clear`.**
  </action>
  <verify>
Run `cd "C:\Users\jinwi\programming_files_NEW\Trace" && .venv/Scripts/python -m pytest tests/ -x -q` -- all 250 tests must pass. The LRU cache is transparent to existing behavior.

Verify: `grep "_compile_snapshot" src/tract/tract.py` returns zero matches.
  </verify>
  <done>
- `self._compile_snapshot` fully replaced by `self._snapshot_cache: OrderedDict`
- TractConfig has `compile_cache_maxsize: int = 8`
- `verify_cache` parameter on Tract.open() and Tract.from_components()
- LRU helpers: `_cache_get`, `_cache_put`, `_cache_clear`
- `compile()` uses LRU with oracle verification support
- `commit()` APPEND uses parent snapshot from LRU
- `record_usage()` uses `dataclasses.replace()` with LRU
- All 250 tests pass
  </done>
</task>

<task type="auto">
  <name>Task 3: EDIT/annotate snapshot patching + oracle tests</name>
  <files>
    src/tract/tract.py
    tests/test_tract.py
  </files>
  <action>
**1. Implement `_patch_snapshot_for_edit()` in `src/tract/tract.py`:**

```python
def _patch_snapshot_for_edit(
    self,
    parent_snapshot: CompileSnapshot,
    new_head_hash: str,
    edit_row: CommitRow,
) -> CompileSnapshot | None:
    """Patch a cached snapshot for an EDIT commit in-memory.

    Finds the message corresponding to the edited target (via edit_target),
    replaces it with the new message, and recounts tokens. No re-aggregation
    needed (aggregation was removed in this phase).

    Returns None if patching is not possible (missing commit_hashes, target
    not found), signaling caller to fall back to full recompile on next compile().
    """
    if not parent_snapshot.commit_hashes:
        return None

    target_hash = edit_row.edit_target
    if target_hash is None:
        return None

    # Find position of the target commit in the snapshot
    try:
        target_idx = list(parent_snapshot.commit_hashes).index(target_hash)
    except ValueError:
        return None  # Target not in snapshot

    assert isinstance(self._compiler, DefaultContextCompiler)
    new_message = self._compiler.build_message_for_commit(edit_row)

    # Replace message at target position
    new_messages = list(parent_snapshot.messages)
    new_messages[target_idx] = new_message

    # Handle generation_config: edit-inherits-original rule
    new_configs = list(parent_snapshot.generation_configs)
    if edit_row.generation_config_json is not None:
        new_configs[target_idx] = dict(edit_row.generation_config_json)  # copy-on-input
    # else: keep original config at target_idx (edit-inherits-original)

    # Recount tokens (no re-aggregation needed)
    messages_dicts = [
        {"role": m.role, "content": m.content}
        if m.name is None
        else {"role": m.role, "content": m.content, "name": m.name}
        for m in new_messages
    ]
    new_token_count = self._token_counter.count_messages(messages_dicts)

    return CompileSnapshot(
        head_hash=new_head_hash,
        messages=tuple(new_messages),
        commit_count=parent_snapshot.commit_count,  # Same count (EDIT replaces, doesn't add)
        token_count=new_token_count,
        token_source=self._tiktoken_source(),
        generation_configs=tuple(new_configs),
        commit_hashes=parent_snapshot.commit_hashes,  # Same positions
    )
```

Add `from tract.storage.schema import CommitRow` to the TYPE_CHECKING imports at the top of tract.py (it may already be there or need adding).

**2. Implement `_patch_snapshot_for_annotate()` in `src/tract/tract.py`:**

```python
def _patch_snapshot_for_annotate(
    self,
    snapshot: CompileSnapshot,
    target_hash: str,
    new_priority: Priority,
) -> CompileSnapshot | None:
    """Patch a cached snapshot for an annotation change.

    SKIP: remove the target's message from the snapshot.
    NORMAL/PINNED on already-included commit: no change needed.
    NORMAL/PINNED on previously-SKIP commit: return None (full recompile).
    """
    if not snapshot.commit_hashes:
        return None

    # Find target position
    target_idx = None
    for i, ch in enumerate(snapshot.commit_hashes):
        if ch == target_hash:
            target_idx = i
            break

    if new_priority == Priority.SKIP:
        if target_idx is None:
            return snapshot  # Already not in snapshot

        # Remove message, config, and hash at target position
        new_messages = list(snapshot.messages)
        new_configs = list(snapshot.generation_configs)
        new_hashes = list(snapshot.commit_hashes)
        del new_messages[target_idx]
        del new_configs[target_idx]
        del new_hashes[target_idx]

        # Recount tokens
        messages_dicts = [
            {"role": m.role, "content": m.content}
            if m.name is None
            else {"role": m.role, "content": m.content, "name": m.name}
            for m in new_messages
        ]
        new_token_count = self._token_counter.count_messages(messages_dicts)

        return CompileSnapshot(
            head_hash=snapshot.head_hash,
            messages=tuple(new_messages),
            commit_count=snapshot.commit_count - 1,
            token_count=new_token_count,
            token_source=self._tiktoken_source(),
            generation_configs=tuple(new_configs),
            commit_hashes=tuple(new_hashes),
        )
    else:
        # NORMAL or PINNED
        if target_idx is not None:
            return snapshot  # Already included, no change
        else:
            return None  # Was skipped, need full recompile (don't have message content)
```

**3. Wire EDIT patching into `commit()` in `src/tract/tract.py`:**

Replace the EDIT path (currently `pass` from Task 2) with:

```python
elif (
    operation == CommitOperation.EDIT
    and isinstance(self._compiler, DefaultContextCompiler)
):
    parent_snapshot = self._cache_get(prev_head) if prev_head else None
    if parent_snapshot is not None:
        edit_row = self._commit_repo.get(info.commit_hash)
        if edit_row is not None:
            patched = self._patch_snapshot_for_edit(parent_snapshot, info.commit_hash, edit_row)
            if patched is not None:
                self._cache_put(info.commit_hash, patched)
    # Do NOT clear cache -- other entries at different HEADs remain valid
    # (the EDIT commit is a new commit not in their chains)
```

Note on DB reads: `self._commit_repo.get(info.commit_hash)` and `build_message_for_commit()`'s internal `blob_repo.get()` are session-cache hits (the commit and blob were just inserted in this session). No actual I/O occurs, but the ORM layer is traversed.

**4. Wire annotate patching into `annotate()` in `src/tract/tract.py`:**

Replace `self._cache_clear()` (from Task 2) with:

```python
# Annotations affect ALL cached snapshots that include the target commit.
# Strategy: clear everything, then optionally re-add a patched current HEAD.
if isinstance(self._compiler, DefaultContextCompiler):
    current_head = self.head
    patched = None
    if current_head:
        snapshot = self._cache_get(current_head)
        if snapshot is not None:
            patched = self._patch_snapshot_for_annotate(snapshot, target_hash, priority)
    self._cache_clear()  # Clear ALL entries (other HEADs may contain the annotated commit)
    if patched is not None:
        self._cache_put(current_head, patched)  # Re-add patched current HEAD
else:
    self._cache_clear()
```

**5. Write tests in `tests/test_tract.py`:**

Add a new test class `TestLRUCompileCacheAndPatching`:

```python
class TestLRUCompileCacheAndPatching:
    """Tests for LRU compile cache, EDIT patching, annotate patching, and oracle verification."""

    def test_lru_cache_hit_at_same_head(self):
        """Two compile() calls at same HEAD: second is cache hit."""
        with Tract.open() as t:
            t.commit(InstructionContent(text="hello"))
            r1 = t.compile()
            r2 = t.compile()
            assert r1.messages == r2.messages
            assert r1.token_count == r2.token_count

    def test_lru_multiple_heads_cached(self):
        """After compiling at different HEADs, both snapshots are in cache."""
        with Tract.open() as t:
            t.commit(InstructionContent(text="first"))
            head_1 = t.head
            t.compile()
            t.commit(DialogueContent(role="user", text="second"))
            head_2 = t.head
            t.compile()
            assert t._cache_get(head_1) is not None
            assert t._cache_get(head_2) is not None

    def test_lru_eviction_at_maxsize(self):
        """Cache evicts LRU entry when maxsize is exceeded."""
        config = TractConfig(compile_cache_maxsize=2)
        with Tract.open(config=config) as t:
            t.commit(InstructionContent(text="a"))
            h1 = t.head
            t.compile()
            t.commit(DialogueContent(role="user", text="b"))
            h2 = t.head
            t.compile()
            t.commit(DialogueContent(role="assistant", text="c"))
            h3 = t.head
            t.compile()
            assert t._cache_get(h1) is None
            assert t._cache_get(h2) is not None
            assert t._cache_get(h3) is not None

    def test_append_incremental_extends_snapshot(self):
        """APPEND commits extend the cached snapshot incrementally."""
        with Tract.open() as t:
            t.commit(InstructionContent(text="system"))
            t.compile()
            t.commit(DialogueContent(role="user", text="hello"))
            r = t.compile()
            assert r.commit_count == 2
            assert len(r.messages) == 2

    def test_edit_patching_matches_full_recompile(self):
        """EDIT patching produces identical result to full recompile (oracle test)."""
        with Tract.open(verify_cache=True) as t:
            c1 = t.commit(InstructionContent(text="System prompt"))
            c2 = t.commit(DialogueContent(role="user", text="Original question"))
            c3 = t.commit(DialogueContent(role="assistant", text="Original answer"))
            t.compile()  # Populate cache with commit_hashes

            t.commit(
                DialogueContent(role="user", text="Edited question"),
                operation=CommitOperation.EDIT,
                edit_target=c2.commit_hash,
            )
            # verify_cache=True asserts patched == fresh
            result = t.compile()
            assert any("Edited question" in m.content for m in result.messages)
            assert not any("Original question" in m.content for m in result.messages)

    def test_edit_patching_preserves_generation_config(self):
        """EDIT without generation_config preserves original's config."""
        with Tract.open(verify_cache=True) as t:
            c1 = t.commit(
                InstructionContent(text="System"),
                generation_config={"temperature": 0.7},
            )
            t.compile()

            t.commit(
                InstructionContent(text="Edited system"),
                operation=CommitOperation.EDIT,
                edit_target=c1.commit_hash,
            )
            result = t.compile()
            assert result.generation_configs[0] == {"temperature": 0.7}

    def test_edit_patching_with_new_config(self):
        """EDIT with its own generation_config replaces the original's config."""
        with Tract.open(verify_cache=True) as t:
            c1 = t.commit(
                InstructionContent(text="System"),
                generation_config={"temperature": 0.7},
            )
            t.compile()

            t.commit(
                InstructionContent(text="Edited system"),
                operation=CommitOperation.EDIT,
                edit_target=c1.commit_hash,
                generation_config={"temperature": 0.9},
            )
            result = t.compile()
            assert result.generation_configs[0] == {"temperature": 0.9}

    def test_annotate_skip_removes_message(self):
        """Annotating with SKIP patches snapshot by removing message."""
        with Tract.open(verify_cache=True) as t:
            c1 = t.commit(InstructionContent(text="System"))
            c2 = t.commit(DialogueContent(role="user", text="Hello"))
            c3 = t.commit(DialogueContent(role="assistant", text="Hi"))
            t.compile()

            t.annotate(c2.commit_hash, Priority.SKIP)
            result = t.compile()
            assert result.commit_count == 2  # c1 and c3 only
            assert not any("Hello" in m.content for m in result.messages)

    def test_annotate_unskip_falls_back_to_recompile(self):
        """Un-skipping a commit triggers full recompile."""
        with Tract.open(verify_cache=True) as t:
            c1 = t.commit(InstructionContent(text="System"))
            c2 = t.commit(DialogueContent(role="user", text="Hello"))
            t.annotate(c2.commit_hash, Priority.SKIP)
            t.compile()

            t.annotate(c2.commit_hash, Priority.NORMAL)
            result = t.compile()
            assert result.commit_count == 2
            assert any("Hello" in m.content for m in result.messages)

    def test_annotate_clears_stale_cache_entries(self):
        """Annotation clears other cached snapshots (they may contain the annotated commit)."""
        with Tract.open() as t:
            t.commit(InstructionContent(text="System"))
            h1 = t.head
            t.compile()  # Cache entry for h1
            t.commit(DialogueContent(role="user", text="Hello"))
            h2 = t.head
            t.compile()  # Cache entry for h2
            assert t._cache_get(h1) is not None
            assert t._cache_get(h2) is not None

            # Annotate a commit -- should clear h1 (stale), keep patched h2
            t.annotate(h1, Priority.SKIP)
            assert t._cache_get(h1) is None  # Cleared
            assert t._cache_get(h2) is not None  # Patched and re-added

    def test_batch_clears_entire_cache(self):
        """batch() clears the entire LRU cache."""
        with Tract.open() as t:
            t.commit(InstructionContent(text="first"))
            t.compile()
            assert len(t._snapshot_cache) == 1
            with t.batch():
                t.commit(DialogueContent(role="user", text="batched"))
            assert len(t._snapshot_cache) == 0

    def test_record_usage_updates_correct_cache_entry(self):
        """record_usage() updates token count in the LRU cache entry."""
        with Tract.open() as t:
            t.commit(InstructionContent(text="hello"))
            t.compile()

            updated = t.record_usage({"prompt_tokens": 42, "completion_tokens": 10, "total_tokens": 52})
            assert updated.token_count == 42
            assert "api:" in updated.token_source

            cached = t._cache_get(t.head)
            assert cached is not None
            assert cached.token_count == 42

    def test_commit_hashes_parallel_to_messages(self):
        """commit_hashes and messages have same length after all operations."""
        with Tract.open() as t:
            c1 = t.commit(InstructionContent(text="a"))
            c2 = t.commit(DialogueContent(role="user", text="b"))
            result = t.compile()
            assert len(result.commit_hashes) == len(result.messages) == 2
            assert result.commit_hashes[0] == c1.commit_hash
            assert result.commit_hashes[1] == c2.commit_hash

    def test_commit_hashes_extend_on_append(self):
        """Incremental APPEND extends commit_hashes."""
        with Tract.open() as t:
            c1 = t.commit(InstructionContent(text="a"))
            t.compile()
            c2 = t.commit(DialogueContent(role="user", text="b"))
            snapshot = t._cache_get(t.head)
            assert snapshot is not None
            assert len(snapshot.commit_hashes) == 2
            assert snapshot.commit_hashes[1] == c2.commit_hash

    def test_verify_cache_flag_default_false(self):
        """verify_cache defaults to False."""
        with Tract.open() as t:
            assert t._verify_cache is False
            t.commit(InstructionContent(text="test"))
            t.compile()  # Should work without oracle check

    def test_consecutive_same_role_with_edit_patching(self):
        """EDIT patching works correctly with consecutive same-role messages (no aggregation)."""
        with Tract.open(verify_cache=True) as t:
            c1 = t.commit(DialogueContent(role="user", text="Q1"))
            c2 = t.commit(DialogueContent(role="user", text="Q2"))
            c3 = t.commit(DialogueContent(role="assistant", text="A1"))
            t.compile()

            # Edit c1's content
            t.commit(
                DialogueContent(role="user", text="Edited Q1"),
                operation=CommitOperation.EDIT,
                edit_target=c1.commit_hash,
            )
            result = t.compile()
            # 3 messages: "Edited Q1", "Q2", "A1" (no aggregation)
            assert len(result.messages) == 3
            assert result.messages[0].content == "Edited Q1"
            assert result.messages[1].content == "Q2"
            assert result.messages[2].content == "A1"
```

Ensure all test imports include `CommitOperation`, `Priority`, `TractConfig`, `InstructionContent`, `DialogueContent` (they should already be imported).
  </action>
  <verify>
Run `cd "C:\Users\jinwi\programming_files_NEW\Trace" && .venv/Scripts/python -m pytest tests/ -x -q` -- all tests must pass (250 existing + ~17 new = ~267 total). Specifically:
- `python -m pytest tests/test_tract.py::TestLRUCompileCacheAndPatching -v` -- all new tests pass
- All oracle tests with `verify_cache=True` pass (patched results identical to full recompile)
  </verify>
  <done>
- EDIT commits patch snapshot in-memory: find message by commit hash, replace, recount tokens -- no chain re-walk, no re-aggregation
- Annotate SKIP removes target message from snapshot; un-skip falls back to full recompile
- Annotation clears entire cache, then re-adds patched current HEAD (fixes stale-entry bug)
- verify_cache=True triggers oracle assertion on every cache hit
- Copy-on-input for generation_config dicts in EDIT patching
- All ~267 tests pass (250 existing + ~17 new)
  </done>
</task>

</tasks>

<verification>
1. `cd "C:\Users\jinwi\programming_files_NEW\Trace" && .venv/Scripts/python -m pytest tests/ -x -q` -- full test suite passes
2. `grep "_compile_snapshot" src/tract/tract.py` returns zero matches (fully replaced by LRU cache)
3. `grep "_aggregate_messages" src/tract/engine/compiler.py` returns zero matches (aggregation removed)
4. `grep "aggregate_same_role" src/tract/models/compiled.py` returns zero matches (field removed)
5. `grep "commit_hashes" src/tract/protocols.py` confirms the field on both CompileSnapshot and CompiledContext
6. `grep "_snapshot_cache" src/tract/tract.py` confirms LRU cache is present
7. `grep "verify_cache" src/tract/tract.py` confirms oracle flag is wired
8. All oracle tests (`verify_cache=True`) pass, proving cache consistency
</verification>

<success_criteria>
1. Same-role consecutive messages are preserved as separate messages in compiled output; `_aggregate_messages()` is removed
2. `CompiledContext.commit_hashes` lists effective commit hashes parallel to messages, populated by the compiler
3. Multiple compile snapshots cached simultaneously via LRU; switching HEAD to a previously-compiled position is a cache hit (O(1))
4. Incremental APPEND still works: new commit's parent matches cached snapshot -> O(1) extend
5. EDIT commits use snapshot patching: find message by commit hash, replace in-memory, recount tokens -- no chain re-walk
6. Annotate (priority change to SKIP) uses snapshot patching; annotation clears stale cache entries for other HEADs
7. batch() remains full cache clear; crash loses cache; DB is always source of truth
8. verify_cache=True cross-checks every cache hit/patch against full recompile (oracle testing)
9. All existing 250 tests pass with updated aggregation assertions (zero regressions)
10. New tests cover LRU eviction, EDIT patching, annotate patching, oracle verification, commit_hashes tracking, and consecutive same-role with EDIT
</success_criteria>

<output>
After completion, create `.planning/phases/01.4-lru-compile-cache-snapshot-patching/01.4-01-SUMMARY.md`
</output>
